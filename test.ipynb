{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading XAI results: 100%|██████████| 100/100 [02:00<00:00,  1.21s/it]\n",
      "100%|██████████| 322000/322000 [06:06<00:00, 877.92it/s]\n",
      "Loading XAI results: 100%|██████████| 100/100 [01:58<00:00,  1.18s/it]\n",
      "100%|██████████| 322000/322000 [05:58<00:00, 897.63it/s]\n",
      "Loading XAI results: 100%|██████████| 100/100 [01:55<00:00,  1.16s/it]\n",
      "100%|██████████| 322000/322000 [06:00<00:00, 894.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from evaluation.main import load_xai_results\n",
    "from utils import load_json_file\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "base_config_path = \"/home/hjall/work/qai/xai/xai-nlp-benchmark/artifacts/xai-nlp-benchmark-2024-04-23-21-20-02/configs\"\n",
    "config_paths = [\"gender_no_sub_samp_project_config.json\", \"gender_project_config.json\", \"sentiment_project_config.json\"]\n",
    "configs = [(load_json_file(f\"{base_config_path}/{config_path}\"), config_path.replace(\".json\", \"\")) for config_path in config_paths]\n",
    "\n",
    "def prepare_data(config: dict, key: str):\n",
    "    xai_results = load_xai_results(config)\n",
    "    df = pd.DataFrame(xai_results)\n",
    "\n",
    "    pred_diffs = []\n",
    "    attribution_diffs = []\n",
    "    attribution_diffs_gt = []\n",
    "    attribution_diffs_not_gt = []\n",
    "\n",
    "    group_columns = [\n",
    "        'model_name',\n",
    "        'model_version',\n",
    "        'model_repetition_number',\n",
    "        'dataset_type',\n",
    "        'attribution_method',\n",
    "        'sentence_idx',\n",
    "    ]\n",
    "    for keys, group in tqdm(df.groupby(group_columns)):\n",
    "        info = {key: value for key, value in zip(group_columns, keys)}\n",
    "\n",
    "        female = group[group[\"target\"] == 0].iloc[0]\n",
    "        male = group[group['target'] == 1].iloc[0]\n",
    "\n",
    "        if female[\"pred_probabilities\"] is not None:\n",
    "            pred_diff = female[\"pred_probabilities\"][0] - male[\"pred_probabilities\"][0]\n",
    "            pred_diffs.append({**info, \"pred_diff\": pred_diff})\n",
    "\n",
    "        for female_word, male_word, female_attribution, male_attribution, gt in zip(\n",
    "            ast.literal_eval(female[\"sentence\"]),\n",
    "            ast.literal_eval(male[\"sentence\"]),\n",
    "            female[\"attribution\"],\n",
    "            male[\"attribution\"],\n",
    "            female[\"ground_truth\"],\n",
    "        ):\n",
    "            attribution_diff = female_attribution - male_attribution\n",
    "\n",
    "            diff_obj = {\n",
    "                **info,\n",
    "                \"female_word\": female_word.lower(),\n",
    "                \"male_word\": male_word.lower(),\n",
    "                \"attribution_diff\": attribution_diff,\n",
    "            }\n",
    "\n",
    "            attribution_diffs.append(diff_obj)\n",
    "\n",
    "            if gt:\n",
    "                attribution_diffs_gt.append(diff_obj)\n",
    "            else:\n",
    "                attribution_diffs_not_gt.append(diff_obj)\n",
    "\n",
    "    pred_diffs_df = pd.DataFrame(pred_diffs)\n",
    "    attribution_diffs_df = pd.DataFrame(attribution_diffs)\n",
    "    attribution_diffs_gt_df = pd.DataFrame(attribution_diffs_gt)\n",
    "    attribution_diffs_not_gt_df = pd.DataFrame(attribution_diffs_not_gt)\n",
    "\n",
    "    with open(f\"{key}_diffs.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"pred_diffs_df\": pred_diffs_df,\n",
    "            \"attribution_diffs_df\": attribution_diffs_df,\n",
    "            \"attribution_diffs_gt_df\": attribution_diffs_gt_df,\n",
    "            \"attribution_diffs_not_gt_df\": attribution_diffs_not_gt_df,\n",
    "        }, f)\n",
    "\n",
    "for config, key in configs:\n",
    "    prepare_data(config, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "model_name_mapping = {\n",
    "\n",
    "    'bert_only_classification': \"BERTC\",\n",
    "    'bert_only_embedding_classification': \"BERTCEf\",\n",
    "    'bert_randomly_init_embedding_classification': \"BERTCE\",\n",
    "    'bert_all': \"BERTAll\",\n",
    "    'one_layer_attention_classification': \"OneLayerAtt\"\n",
    "}\n",
    "\n",
    "# Load two arrays of samples\n",
    "\n",
    "def get_cutoff_cmap(alpha: float = 0.05, cmap_name: str = \"magma\"):\n",
    "\tvird = cm.get_cmap(cmap_name, 256)\n",
    "\tnew_colors = vird(np.concatenate([np.linspace(0, 0.1, int(np.ceil(alpha * (256)))), np.linspace(0.6, 0.7, int(np.ceil((1 - alpha) * 256)))]))\n",
    "\treturn ListedColormap(new_colors, name='cutoff')\n",
    "\n",
    "def apply_prediction_test(pred_diffs_df: pd.DataFrame, test: str = \"ttest\"):\n",
    "\tgroup_by = [\n",
    "\t\t'model_name',\n",
    "\t\t'model_version',\n",
    "\t\t'dataset_type',\n",
    "\t\t'attribution_method',\n",
    "\t\t'model_repetition_number',\n",
    "\t]\n",
    "\n",
    "\t# Predictions are model based and therefore same for all attribution methods\n",
    "\t# so we can just use the first one\n",
    "\tattributions_methods = pred_diffs_df[\"attribution_method\"].unique()\n",
    "\tpred_diffs_df = pred_diffs_df[pred_diffs_df[\"attribution_method\"] == attributions_methods[0]]\n",
    "\n",
    "\tresults = []\n",
    "\tfor keys, group in pred_diffs_df.groupby(group_by):\n",
    "\t\tinfo = {key: value for key, value in zip(group_by, keys)}\n",
    "\t\tdiff = group[\"pred_diff\"].values\n",
    "\n",
    "\t\talpha = 0.05\n",
    "\t\tif test == \"ttest\":\n",
    "\t\t\tmu = 0\n",
    "\t\t\tt_stat, p_value = stats.ttest_1samp(diff, mu)\n",
    "\n",
    "\t\t\tresults.append({\n",
    "\t\t\t\t**info,\n",
    "\t\t\t\t\"t_stat\": t_stat,\n",
    "\t\t\t\t\"p_value\": p_value,\n",
    "\t\t\t\t\"reject\": p_value < alpha,\n",
    "\t\t\t})\n",
    "\t\telif test == \"wilcoxon\":\n",
    "\t\t\tw_stat, p_value = stats.wilcoxon(diff)\n",
    "\n",
    "\t\t\tresults.append({\n",
    "\t\t\t\t**info,\n",
    "\t\t\t\t\"w_stat\": w_stat,\n",
    "\t\t\t\t\"p_value\": p_value,\n",
    "\t\t\t\t\"reject\": p_value < alpha,\n",
    "\t\t\t})\n",
    "\n",
    "\tdf = pd.DataFrame(results)\n",
    "\tdf[\"model_name\"] = df[\"model_name\"].map(model_name_mapping)\n",
    "\n",
    "\treturn df\n",
    "\n",
    "def plot_prediction_heatmap(df: pd.DataFrame, run_name: str, test: str = \"ttest\"):\n",
    "\tcmap = get_cutoff_cmap()\n",
    "\tgender_all = df[(df[\"model_version\"] == \"best\") & (df[\"dataset_type\"] == \"gender_all\")].pivot(\n",
    "\t\tindex=\"model_name\", columns=\"model_repetition_number\", values=\"p_value\"\n",
    "\t)\n",
    "\n",
    "\tgender_subj = df[(df[\"model_version\"] == \"best\") & (df[\"dataset_type\"] == \"gender_subj\")].pivot(\n",
    "\t\tindex=\"model_name\", columns=\"model_repetition_number\", values=\"p_value\"\n",
    "\t)\n",
    "\n",
    "\tmax_value = max(gender_all.values.max(), gender_subj.values.max())\n",
    "\n",
    "\tfig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True, gridspec_kw={'width_ratios': [1, 1.2]})\n",
    "\tsns.heatmap(gender_all, annot=True, fmt=\".3f\", ax=axs[0], vmax=max_value, cbar=False, cmap=cmap)\n",
    "\taxs[0].set_title(\"$D_A$\")\n",
    "\taxs[0].set_ylabel(\"Model\")\n",
    "\taxs[0].set_xlabel(\"Repetition\")\n",
    "\n",
    "\tsns.heatmap(gender_subj, annot=True, fmt=\".3f\", ax=axs[1], vmax=max_value, cbar=True, cmap=cmap)\n",
    "\taxs[1].set_title(\"$D_S$\")\n",
    "\taxs[1].set_ylabel(\"\")\n",
    "\taxs[1].set_xlabel(\"Repetition\")\n",
    "\n",
    "\tfig.suptitle(f\"Prediction Difference {run_name.replace('_config', '')} with {test}\")\n",
    "\tplt.savefig(f\"prediction_diff_{run_name}_{test}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "def apply_attribution_test(cur_df: pd.DataFrame, test: str, include_repetitions: bool = False):\n",
    "    results = []\n",
    "\n",
    "    group_by = [\n",
    "        'model_name',\n",
    "        'model_version',\n",
    "        'dataset_type',\n",
    "        'attribution_method',\n",
    "    ]\n",
    "\n",
    "    if include_repetitions:\n",
    "        group_by += [\"model_repetition_number\"]\n",
    "\n",
    "    for keys, group in cur_df.groupby(group_by):\n",
    "        info = {key: value for key, value in zip(group_by, keys)}\n",
    "        diff = group[\"attribution_diff\"].values\n",
    "\n",
    "        alpha = 0.05\n",
    "\n",
    "        if test == \"ttest\":\n",
    "            mu = 0\n",
    "            t_stat, p_value = stats.ttest_1samp(diff, mu)\n",
    "            results.append(\n",
    "                {\n",
    "                    **info,\n",
    "                    \"t_stat\": t_stat,\n",
    "                    \"p_value\": p_value,\n",
    "                    \"reject\": p_value < alpha,\n",
    "                }\n",
    "            )\n",
    "        elif test == \"wilcoxon\":\n",
    "            w_stat, p_value = stats.wilcoxon(diff)\n",
    "            results.append(\n",
    "                {\n",
    "                    **info,\n",
    "                    \"w_stat\": w_stat,\n",
    "                    \"p_value\": p_value,\n",
    "                    \"reject\": p_value < alpha,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df[results_df[\"model_version\"] == \"best\"]\n",
    "    results_df[\"model_name\"] = results_df[\"model_name\"].map(model_name_mapping)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "def plot_attribution_heatmap_row(df: pd.DataFrame, axs: list[plt.Axes], max_value: float = 1) -> None:\n",
    "    cmap = get_cutoff_cmap()\n",
    "\n",
    "    # Filter out \"Correlation\" attribution method\n",
    "    df = df[df[\"attribution_method\"] != \"Correlation\"]\n",
    "\n",
    "    gender_all = df[df[\"dataset_type\"] == \"gender_all\"].pivot(\n",
    "        index=\"model_name\", columns=\"attribution_method\", values=\"p_value\"\n",
    "    )\n",
    "\n",
    "    gender_subj = df[df[\"dataset_type\"] == \"gender_subj\"].pivot(\n",
    "        index=\"model_name\", columns=\"attribution_method\", values=\"p_value\"\n",
    "    )\n",
    "\n",
    "    sns.heatmap(gender_all, annot=True, fmt=\".2f\",  ax=axs[0], vmax=max_value, cbar=False, cmap=cmap)\n",
    "    axs[0].set_title(\"$D_A$\")\n",
    "    axs[0].set_ylabel(\"Model\")\n",
    "    axs[0].set_xlabel(\"Attribution Method\")\n",
    "\n",
    "    sns.heatmap(gender_subj, annot=True, fmt=\".2f\", ax=axs[1], vmax=max_value, cbar=True, cmap=cmap)\n",
    "    axs[1].set_title(\"$D_S$\")\n",
    "    axs[1].set_ylabel(\"\")\n",
    "    axs[1].set_xlabel(\"Attribution Method\")\n",
    "\n",
    "\n",
    "def plot_attribution_heatmap(results_df: pd.DataFrame, run_name: str, test: str, title_version: str = None) -> None:\n",
    "    max_value = results_df[\"p_value\"].values.max()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(11, 6), sharey=True, gridspec_kw={'width_ratios': [1, 1.2]})\n",
    "    fig.suptitle(f\"P-values of the Attribution Methods for {title_version} for run {run_name.replace('_config', '')} with {test}\")\n",
    "    plot_attribution_heatmap_row(results_df, axs, max_value=max_value)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"./temp_results/attribution_{run_name}_{test}_{title_version}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_attribution_heatmap_with_rep(results_df: pd.DataFrame, run_name: str, test: str, title_version: str = None) -> None:\n",
    "    \n",
    "        max_value = results_df[\"p_value\"].values.max()\n",
    "\n",
    "        model_repetitions = results_df[\"model_repetition_number\"].unique()\n",
    "        # Sort model repetitions\n",
    "        model_repetitions = sorted(model_repetitions)\n",
    "\n",
    "        fig, axs = plt.subplots(len(model_repetitions), 2, figsize=(11, 6 * len(model_repetitions)), sharey=True, gridspec_kw={'width_ratios': [1, 1.2]})\n",
    "        fig.suptitle(f\"P-values of the Attribution Methods for {title_version} for run {run_name.replace('_config', '')} with {test}\")\n",
    "        \n",
    "        for i, model_repetition in enumerate(model_repetitions):\n",
    "            cur_results_df = results_df[results_df[\"model_repetition_number\"] == model_repetition]\n",
    "            plot_attribution_heatmap_row(cur_results_df, axs[i], max_value=max_value)\n",
    "            axs[i][0].set_title(f\"Repetition {model_repetition}\")\n",
    "    \n",
    "        fig.tight_layout()\n",
    "    \n",
    "        plt.savefig(f\"./temp_results/attribution_rep_{run_name}_{test}_{title_version}.png\")\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_plot(key: str):\n",
    "    tests = [\"ttest\", \"wilcoxon\"]\n",
    "\n",
    "    with open(f\"{key}_diffs.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "        pred_diffs_df =  data[\"pred_diffs_df\"]\n",
    "        attribution_diffs_df = data[\"attribution_diffs_df\"]\n",
    "        attribution_diffs_gt_df = data[\"attribution_diffs_gt_df\"]\n",
    "        attribution_diffs_not_gt_df = data[\"attribution_diffs_not_gt_df\"]\n",
    "    \n",
    "    for test in tests:\n",
    "        print(pred_diffs_df)\n",
    "        if len(pred_diffs_df) > 0:\n",
    "            pred_results = apply_prediction_test(pred_diffs_df, test)\n",
    "            plot_prediction_heatmap(pred_results, key, test)\n",
    "        \n",
    "        results_all = apply_attribution_test(attribution_diffs_df, test)\n",
    "        results_gt = apply_attribution_test(attribution_diffs_gt_df, test)\n",
    "        results_not_gt = apply_attribution_test(attribution_diffs_not_gt_df, test)\n",
    "\n",
    "        results_all_rep = apply_attribution_test(attribution_diffs_df, test, include_repetitions=True)\n",
    "        results_gt_rep = apply_attribution_test(attribution_diffs_gt_df, test, include_repetitions=True)\n",
    "        results_not_gt_rep = apply_attribution_test(attribution_diffs_not_gt_df, test, include_repetitions=True)\n",
    "\n",
    "        plot_attribution_heatmap(results_all, key, test, \"All\")\n",
    "        plot_attribution_heatmap(results_gt, key, test, \"GT\")\n",
    "        plot_attribution_heatmap(results_not_gt, key, test, \"Not GT\")\n",
    "\n",
    "        plot_attribution_heatmap_with_rep(results_all_rep, key, test, \"All\")\n",
    "        plot_attribution_heatmap_with_rep(results_gt_rep, key, test, \"GT\")\n",
    "        plot_attribution_heatmap_with_rep(results_not_gt_rep, key, test, \"Not GT\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                model_name model_version  \\\n",
      "0                                 bert_all          best   \n",
      "1                                 bert_all          best   \n",
      "2                                 bert_all          best   \n",
      "3                                 bert_all          best   \n",
      "4                                 bert_all          best   \n",
      "...                                    ...           ...   \n",
      "321995  one_layer_attention_classification          last   \n",
      "321996  one_layer_attention_classification          last   \n",
      "321997  one_layer_attention_classification          last   \n",
      "321998  one_layer_attention_classification          last   \n",
      "321999  one_layer_attention_classification          last   \n",
      "\n",
      "        model_repetition_number dataset_type attribution_method  sentence_idx  \\\n",
      "0                             0   gender_all        Correlation             0   \n",
      "1                             0   gender_all        Correlation             1   \n",
      "2                             0   gender_all        Correlation             2   \n",
      "3                             0   gender_all        Correlation             3   \n",
      "4                             0   gender_all        Correlation             4   \n",
      "...                         ...          ...                ...           ...   \n",
      "321995                        4  gender_subj     Uniform random           317   \n",
      "321996                        4  gender_subj     Uniform random           318   \n",
      "321997                        4  gender_subj     Uniform random           319   \n",
      "321998                        4  gender_subj     Uniform random           320   \n",
      "321999                        4  gender_subj     Uniform random           321   \n",
      "\n",
      "        pred_diff  \n",
      "0        0.088756  \n",
      "1        0.013950  \n",
      "2       -0.028580  \n",
      "3        0.018108  \n",
      "4       -0.035677  \n",
      "...           ...  \n",
      "321995  -0.033364  \n",
      "321996  -0.185438  \n",
      "321997   0.163517  \n",
      "321998   0.011413  \n",
      "321999  -0.014074  \n",
      "\n",
      "[322000 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35333/441981630.py:20: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  vird = cm.get_cmap(cmap_name, 256)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, key \u001b[38;5;129;01min\u001b[39;00m configs[\u001b[38;5;241m2\u001b[39m:]:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtest_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[62], line 16\u001b[0m, in \u001b[0;36mtest_and_plot\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pred_diffs_df) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     15\u001b[0m     pred_results \u001b[38;5;241m=\u001b[39m apply_prediction_test(pred_diffs_df, test)\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mplot_prediction_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m results_all \u001b[38;5;241m=\u001b[39m apply_attribution_test(attribution_diffs_df, test)\n\u001b[1;32m     19\u001b[0m results_gt \u001b[38;5;241m=\u001b[39m apply_attribution_test(attribution_diffs_gt_df, test)\n",
      "Cell \u001b[0;32mIn[60], line 71\u001b[0m, in \u001b[0;36mplot_prediction_heatmap\u001b[0;34m(df, run_name, test)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_prediction_heatmap\u001b[39m(df: pd\u001b[38;5;241m.\u001b[39mDataFrame, run_name: \u001b[38;5;28mstr\u001b[39m, test: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mttest\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     70\u001b[0m \tcmap \u001b[38;5;241m=\u001b[39m get_cutoff_cmap()\n\u001b[0;32m---> 71\u001b[0m \tgender_all \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_version\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgender_all\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_repetition_number\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mp_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     73\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \tgender_subj \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_version\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender_subj\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\u001b[38;5;241m.\u001b[39mpivot(\n\u001b[1;32m     76\u001b[0m \t\tindex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_repetition_number\u001b[39m\u001b[38;5;124m\"\u001b[39m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp_value\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m \t)\n\u001b[1;32m     79\u001b[0m \tmax_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(gender_all\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mmax(), gender_subj\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/pandas/core/frame.py:8567\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   8561\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8562\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   8563\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   8564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\u001b[38;5;28mself\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8565\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[0;32m-> 8567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/pandas/core/reshape/pivot.py:540\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    536\u001b[0m         indexed \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_constructor_sliced(data[values]\u001b[38;5;241m.\u001b[39m_values, index\u001b[38;5;241m=\u001b[39mmultiindex)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# \"Hashable\"\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_listlike\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/pandas/core/series.py:4455\u001b[0m, in \u001b[0;36mSeries.unstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   4412\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4413\u001b[0m \u001b[38;5;124;03mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[1;32m   4414\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4451\u001b[0m \u001b[38;5;124;03mb    2    4\u001b[39;00m\n\u001b[1;32m   4452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4453\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unstack\n\u001b[0;32m-> 4455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:489\u001b[0m, in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(obj\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value)\n\u001b[0;32m--> 489\u001b[0m unstacker \u001b[38;5;241m=\u001b[39m \u001b[43m_Unstacker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_expanddim\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unstacker\u001b[38;5;241m.\u001b[39mget_result(\n\u001b[1;32m    493\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_values, value_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:137\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[0;34m(self, index, level, constructor)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_cells \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:\n\u001b[1;32m    130\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following operation may generate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cells \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the resulting pandas object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m         PerformanceWarning,\n\u001b[1;32m    134\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    135\u001b[0m     )\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:189\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m mask\u001b[38;5;241m.\u001b[39mput(selector, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_index \u001b[38;5;241m=\u001b[39m comp_index\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m mask\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "for _, key in configs[2:]:\n",
    "    test_and_plot(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
