{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7df40d",
   "metadata": {
    "id": "9f7df40d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = \"./data\"\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4fdc8",
   "metadata": {
    "id": "1fd4fdc8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start from the labeled phrases\n",
    "df_original = pd.read_excel(os.path.join(DATA_PATH, \"all_phrases.xlsx\"), index_col=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194cd17f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "194cd17f",
    "outputId": "1f3a4c90-1305-4a6c-a4c6-c50f5b9d5b99",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_original.copy()\n",
    "df = df[df[0].isna()]  # here I deleted all the phrases that should be checked\n",
    "\n",
    "original_phrases = (\n",
    "    df[df[2] == \"Original\"]\n",
    "    .drop([0, 1, 2], axis=1)\n",
    "    .reset_index()\n",
    "    .drop([\"index\"], axis=1)\n",
    ")\n",
    "\n",
    "# ground_truths\n",
    "all_female_phrases_gt = (\n",
    "    df[df[2] == \"All Female\"]\n",
    "    .drop([0, 1, 2], axis=1)\n",
    "    .reset_index()\n",
    "    .drop([\"index\"], axis=1)\n",
    ")\n",
    "\n",
    "all_male_phrases_gt = (\n",
    "    df[df[2] == \"All Male\"]\n",
    "    .drop([0, 1, 2], axis=1)\n",
    "    .reset_index()\n",
    "    .drop([\"index\"], axis=1)\n",
    ")\n",
    "\n",
    "female_sub_phrases_gt = (\n",
    "    df[df[2] == \"Subject Female\"]\n",
    "    .drop([0, 1, 2], axis=1)\n",
    "    .reset_index()\n",
    "    .drop([\"index\"], axis=1)\n",
    ")\n",
    "\n",
    "male_sub_phrases_gt = (\n",
    "    df[df[2] == \"Subject Male\"]\n",
    "    .drop([0, 1, 2], axis=1)\n",
    "    .reset_index()\n",
    "    .drop([\"index\"], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r0ZXW2jJwVBp",
   "metadata": {
    "id": "r0ZXW2jJwVBp"
   },
   "source": [
    "# ===================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1e870",
   "metadata": {
    "id": "7fa1e870",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change_words(original_phrase, ground_truth):\n",
    "    \"\"\"\n",
    "    Replaces the words in the original phrase with the words in the ground truth\n",
    "    \"\"\"\n",
    "\n",
    "    new_phrase = original_phrase.copy()\n",
    "    for j in list(ground_truth.index):\n",
    "        if not pd.isna(ground_truth.loc[j]):\n",
    "            new_phrase.loc[j] = ground_truth.loc[j]\n",
    "\n",
    "    return list(new_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85372cea",
   "metadata": {
    "id": "85372cea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_fem = []\n",
    "all_male = []\n",
    "subj_fem = []\n",
    "subj_male = []\n",
    "for idx in list(original_phrases.index):\n",
    "    all_fem_phrase = change_words(\n",
    "        original_phrases.loc[idx], all_female_phrases_gt.loc[idx]\n",
    "    )\n",
    "    all_fem.append(all_fem_phrase)\n",
    "\n",
    "    all_male_phrase = change_words(\n",
    "        original_phrases.loc[idx], all_male_phrases_gt.loc[idx]\n",
    "    )\n",
    "    all_male.append(all_male_phrase)\n",
    "\n",
    "    subj_fem_phrase = change_words(\n",
    "        original_phrases.loc[idx], female_sub_phrases_gt.loc[idx]\n",
    "    )\n",
    "    subj_fem.append(subj_fem_phrase)\n",
    "\n",
    "    subj_male_phrase = change_words(\n",
    "        original_phrases.loc[idx], male_sub_phrases_gt.loc[idx]\n",
    "    )\n",
    "    subj_male.append(subj_male_phrase)\n",
    "\n",
    "all_fem = pd.DataFrame(all_fem)\n",
    "all_male = pd.DataFrame(all_male)\n",
    "subj_fem = pd.DataFrame(subj_fem)\n",
    "subj_male = pd.DataFrame(subj_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea030995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example how the phrases look like\n",
    "\n",
    "example_df = pd.DataFrame(\n",
    "    [\n",
    "        list(original_phrases.loc[0]),\n",
    "        list(all_female_phrases_gt.loc[0]),\n",
    "        list(all_fem.loc[0]),\n",
    "    ],\n",
    "    index=[\"Original Phrase\", \"+ Female All Ground Truth\", \"= Female Phrase\"],\n",
    ")\n",
    "\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7fbb53",
   "metadata": {
    "id": "ac7fbb53"
   },
   "source": [
    "## Changes to the names and surnames\n",
    "+ for the surnames I deleted the ones that had \"'\" such as O'brain (that's why there are only 248 surnames and not 250)\n",
    "+ for both I deleted the (sur)names that ended in \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b40206",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4b40206",
    "outputId": "0dfe9b46-28ef-4475-b252-d75e577682b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "female_names = pd.read_csv(os.path.join(DATA_PATH, 'Top250Female1996-2019.txt'), lineterminator=\"\\n\", header=None)\n",
    "male_names = pd.read_csv(os.path.join(DATA_PATH, 'Top250Male1996-2019.txt'), lineterminator=\"\\n\", header=None)\n",
    "surnames = pd.read_csv(os.path.join(DATA_PATH, 'Top250Surnames1991-2000.txt'), lineterminator=\"\\n\", header=None) \n",
    "\n",
    "print(female_names.shape,male_names.shape,surnames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfddab1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bfddab1",
    "outputId": "bdbe1cf4-fb0b-405d-aa04-aeeddef2e33e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "female_names = pd.DataFrame([name for name in list(female_names[0]) if name[-1] != \"s\"])\n",
    "male_names = pd.DataFrame([name for name in list(male_names[0]) if name[-1] != \"s\"])\n",
    "surnames = pd.DataFrame(\n",
    "    [name for name in list(surnames[0]) if (name[-1] != \"s\" or name.find(\"'\") != -1)]\n",
    ")\n",
    "\n",
    "female_names = list(name[0] for name in female_names.values)\n",
    "male_names = list(name[0] for name in male_names.values)\n",
    "surnames = list(name[0] for name in surnames.values)\n",
    "\n",
    "print(len(female_names), len(male_names), len(surnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76960d18",
   "metadata": {
    "id": "76960d18",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change_names(phrase):\n",
    "    \"\"\"\n",
    "    Replace \"name_male_1\", \"name_female_1\" and \"surname_1\" / \"surname_1_pl\" with random names from the lists.\n",
    "\n",
    "    The number determines the index of the name in the list and \"surname_1_pl\" is the plural form of the surname.\n",
    "    \"\"\"\n",
    "    p = phrase.copy()\n",
    "\n",
    "    for word_idx in list(p.index):\n",
    "        if str(p.loc[word_idx]).startswith(\"name_male\"):\n",
    "            # Replace male name\n",
    "            idx = int(p.loc[word_idx][-1]) - 1\n",
    "            p.loc[word_idx] = male_names[idx]\n",
    "        elif str(p.loc[word_idx]).startswith(\"name_female\"):\n",
    "            # Replace female name\n",
    "            idx = int(p.loc[word_idx][-1]) - 1\n",
    "            p.loc[word_idx] = female_names[idx]\n",
    "        elif str(p.loc[word_idx]).startswith(\"surname\"):\n",
    "            if p.loc[word_idx][-2:] == \"pl\":\n",
    "                # Replace plural surname\n",
    "                idx = int(p.loc[word_idx][-4]) - 1\n",
    "                p.loc[word_idx] = surnames[idx] + \"s\"\n",
    "            else:\n",
    "                # Replace singular surname\n",
    "                idx = int(p.loc[word_idx][-1]) - 1\n",
    "                p.loc[word_idx] = surnames[idx]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f675fa",
   "metadata": {
    "id": "c3f675fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_all_fem = []\n",
    "final_all_male = []\n",
    "final_subj_fem = []\n",
    "final_subj_male = []\n",
    "for idx in all_fem.index:\n",
    "    random.shuffle(female_names)\n",
    "    random.shuffle(male_names)\n",
    "    random.shuffle(surnames)\n",
    "\n",
    "    phrase1 = change_names(all_fem.iloc[idx])\n",
    "    final_all_fem.append(phrase1)\n",
    "\n",
    "    phrase2 = change_names(all_male.iloc[idx])\n",
    "    final_all_male.append(phrase2)\n",
    "\n",
    "    phrase3 = change_names(subj_fem.iloc[idx])\n",
    "    final_subj_fem.append(phrase3)\n",
    "\n",
    "    phrase4 = change_names(subj_male.iloc[idx])\n",
    "    final_subj_male.append(phrase4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d35ca",
   "metadata": {
    "id": "3c2d35ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_all_fem = pd.DataFrame(final_all_fem)\n",
    "final_all_male = pd.DataFrame(final_all_male)\n",
    "final_subj_fem = pd.DataFrame(final_subj_fem)\n",
    "final_subj_male = pd.DataFrame(final_subj_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa9f5c",
   "metadata": {
    "id": "4efa9f5c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_train_val_datasets(final_male, final_female):\n",
    "    SEED = 1234\n",
    "    random.seed(SEED)\n",
    "    frac = 0.8\n",
    "\n",
    "    # creating training and validation indexes\n",
    "    indexes = list(final_male.index)\n",
    "    train_idx = random.sample(indexes, k=int(len(indexes) * frac))\n",
    "    val_idx = [i for i in list(range(len(final_male))) if i not in train_idx]\n",
    "\n",
    "    # trianing dataset\n",
    "    # selects the lines for the training dataset\n",
    "    # these are two datasets that will then be used to choose between female and male after\n",
    "    df_training_male = final_male.iloc[train_idx]\n",
    "    df_training_female = final_female.iloc[train_idx]\n",
    "\n",
    "    # creating training dataset\n",
    "    indexes_male = random.sample(\n",
    "        list(df_training_male.index), k=int(len(list(df_training_male.index)) / 2)\n",
    "    )\n",
    "    indexes_female = [i for i in train_idx if i not in indexes_male]\n",
    "\n",
    "    # selects the lines that are female or male from the training datasets\n",
    "    df_male = df_training_male.loc[indexes_male]\n",
    "    df_female = df_training_female.loc[indexes_female]\n",
    "\n",
    "    df_male.insert(0, \"target\", 1)\n",
    "    df_female.insert(0, \"target\", 0)\n",
    "\n",
    "    # concatenate dataframes to create dataset\n",
    "    training_df = pd.concat([df_male, df_female]).sort_index()\n",
    "\n",
    "    # validation dataset\n",
    "    # selects the lines for the validation dataset\n",
    "    df_validation_male = final_male.iloc[val_idx]\n",
    "    df_validation_female = final_female.iloc[val_idx]\n",
    "\n",
    "    df_validation_male.insert(0, \"target\", np.ones(len(df_validation_male)))\n",
    "    df_validation_female.insert(0, \"target\", np.zeros(len(df_validation_female)))\n",
    "\n",
    "    return training_df, df_validation_male, df_validation_female, val_idx, train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7d55d",
   "metadata": {
    "id": "a4c7d55d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    training_df_all,\n",
    "    df_validation_male_all,\n",
    "    df_validation_female_all,\n",
    "    val_idx_all,\n",
    "    train_idx_all,\n",
    ") = create_train_val_datasets(final_all_male, final_all_fem)\n",
    "\n",
    "(\n",
    "    training_df_subj,\n",
    "    df_validation_male_subj,\n",
    "    df_validation_female_subj,\n",
    "    val_idx_subj,\n",
    "    train_idx_subj,\n",
    ") = create_train_val_datasets(final_subj_male, final_subj_fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e875f38",
   "metadata": {
    "id": "9e875f38",
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"training_df_all.pkl\": training_df_all,\n",
    "    \"df_validation_male_all.pkl\": df_validation_male_all,\n",
    "    \"df_validation_female_all.pkl\": df_validation_female_all,\n",
    "    \"training_df_subj.pkl\": training_df_subj,\n",
    "    \"df_validation_male_subj.pkl\": df_validation_male_subj,\n",
    "    \"df_validation_female_subj.pkl\": df_validation_female_subj\n",
    "}\n",
    "\n",
    "for filename, df in files.items():\n",
    "    with open(os.path.join(DATA_PATH, filename), \"wb\") as f:\n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af6392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gt(original_phrases, female_gt, male_gt):\n",
    "    gt_out = pd.DataFrame(np.zeros(female_sub_phrases_gt.shape))\n",
    "\n",
    "    for i in range(len(original_phrases)):\n",
    "        phrase_f = female_gt.iloc[i]\n",
    "        phrase_m = male_gt.iloc[i]\n",
    "\n",
    "        for word_idx in range(len(phrase_f)):\n",
    "            word_idx += 3\n",
    "            if str(phrase_f[word_idx]) != str(phrase_m[word_idx]):\n",
    "                gt_out.iloc[i][word_idx] = 1\n",
    "    \n",
    "    return gt_out\n",
    "\n",
    "\n",
    "# Ground truth for change type \"all\"\n",
    "gt_all = create_gt(original_phrases, all_female_phrases_gt, all_male_phrases_gt)\n",
    "gt_all_val = gt_all.loc[val_idx_all]\n",
    "gt_all_train = gt_all.loc[train_idx_all]\n",
    "\n",
    "\n",
    "# Ground truth for change type \"subj\"\n",
    "gt_subj = create_gt(original_phrases, female_sub_phrases_gt, male_sub_phrases_gt)\n",
    "gt_subj_val = gt_subj.loc[val_idx_subj]\n",
    "gt_subj_train = gt_subj.loc[train_idx_subj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afAqTBtDFtKc",
   "metadata": {
    "id": "afAqTBtDFtKc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_files = {\n",
    "    \"gt_subj_val.pkl\": gt_subj_val,\n",
    "    \"gt_subj_train.pkl\": gt_subj_train,\n",
    "    \"gt_all_val.pkl\": gt_all_val,\n",
    "    \"gt_all_train.pkl\": gt_all_train\n",
    "}\n",
    "\n",
    "for filename, df in gt_files.items():\n",
    "    with open(os.path.join(DATA_PATH, filename), \"wb\") as f:\n",
    "        pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
