{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "9f7df40d",
            "metadata": {
                "id": "9f7df40d"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import random\n",
                "import pickle\n",
                "import os\n",
                "\n",
                "SEED = 1234\n",
                "random.seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "\n",
                "DATA_PATH = \"./data\"\n",
                "OUTPUT_PATH = \"../raw\"\n",
                "os.makedirs(DATA_PATH, exist_ok=True)\n",
                "os.makedirs(OUTPUT_PATH, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "1fd4fdc8",
            "metadata": {
                "id": "1fd4fdc8"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/hjall/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
                        "  warn(msg)\n"
                    ]
                }
            ],
            "source": [
                "# Start from the labeled phrases\n",
                "df_original = pd.read_excel(os.path.join(DATA_PATH, \"all_phrases.xlsx\"), index_col=None, header=None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "194cd17f",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "194cd17f",
                "outputId": "1f3a4c90-1305-4a6c-a4c6-c50f5b9d5b99"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/hjall/work/qai/xai/xai-nlp-benchmark/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
                        "  warn(msg)\n"
                    ]
                }
            ],
            "source": [
                "from dataclasses import dataclass\n",
                "\n",
                "@dataclass\n",
                "class Phrases:\n",
                "    original: pd.DataFrame\n",
                "    all_female: pd.DataFrame\n",
                "    all_male: pd.DataFrame\n",
                "    subj_female: pd.DataFrame\n",
                "    subj_male: pd.DataFrame\n",
                "    idx: pd.DataFrame = None\n",
                "    resp: pd.DataFrame = None\n",
                "\n",
                "def filter_row_drop(df: pd.DataFrame, key: str):\n",
                "    return (\n",
                "        df[df[2] == key]\n",
                "        .drop([0, 1, 2], axis=1)\n",
                "        .reset_index()\n",
                "        .drop([\"index\"], axis=1)\n",
                "    )\n",
                "\n",
                "def filter_row(df: pd.DataFrame, key: str):\n",
                "    return (\n",
                "        df[df[2] == key]\n",
                "        .reset_index()\n",
                "        .drop([\"index\"], axis=1)\n",
                "    )\n",
                "\n",
                "def load_excel(path: str, new_format: bool):\n",
                "    df = pd.read_excel(path, index_col=None, header=None)\n",
                "\n",
                "    if new_format:\n",
                "        # Drop first row\n",
                "        df = df.drop([0], axis=0)\n",
                "    else:\n",
                "        df = df[df[0].isna()]  # here I deleted all the phrases that should be checked\n",
                "\n",
                "    return Phrases(\n",
                "        original=filter_row_drop(df, \"Original\"),\n",
                "        all_female=filter_row_drop(df, \"All Female\"),\n",
                "        all_male=filter_row_drop(df, \"All Male\"),\n",
                "        subj_female=filter_row_drop(df, \"Subject Female\"),\n",
                "        subj_male=filter_row_drop(df, \"Subject Male\"),\n",
                "        idx=filter_row(df, \"Original\")[0],\n",
                "        resp=filter_row(df, \"Original\")[1]\n",
                "    )\n",
                "\n",
                "phrases = load_excel(os.path.join(DATA_PATH, \"all_phrases.xlsx\"), new_format=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "e8c941f8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>original</th>\n",
                            "      <th>all_female</th>\n",
                            "      <th>all_male</th>\n",
                            "      <th>subj_female</th>\n",
                            "      <th>subj_male</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>On</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>the</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>other</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>hand</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>,</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>Oliver</td>\n",
                            "      <td>name_female_1</td>\n",
                            "      <td>name_male_1</td>\n",
                            "      <td>name_female_1</td>\n",
                            "      <td>name_male_1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>proves</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>to</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>be</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>12</th>\n",
                            "      <td>of</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13</th>\n",
                            "      <td>gentle</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>birth</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15</th>\n",
                            "      <td>for</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>16</th>\n",
                            "      <td>a</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>17</th>\n",
                            "      <td>workhouse</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>18</th>\n",
                            "      <td>boy</td>\n",
                            "      <td>girl</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>girl</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19</th>\n",
                            "      <td>.</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>20</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>22</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>23</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>24</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>26</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>27</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>29</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>30</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>31</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "     original     all_female     all_male    subj_female    subj_male\n",
                            "3          On            NaN          NaN            NaN          NaN\n",
                            "4         the            NaN          NaN            NaN          NaN\n",
                            "5       other            NaN          NaN            NaN          NaN\n",
                            "6        hand            NaN          NaN            NaN          NaN\n",
                            "7           ,            NaN          NaN            NaN          NaN\n",
                            "8      Oliver  name_female_1  name_male_1  name_female_1  name_male_1\n",
                            "9      proves            NaN          NaN            NaN          NaN\n",
                            "10         to            NaN          NaN            NaN          NaN\n",
                            "11         be            NaN          NaN            NaN          NaN\n",
                            "12         of            NaN          NaN            NaN          NaN\n",
                            "13     gentle            NaN          NaN            NaN          NaN\n",
                            "14      birth            NaN          NaN            NaN          NaN\n",
                            "15        for            NaN          NaN            NaN          NaN\n",
                            "16          a            NaN          NaN            NaN          NaN\n",
                            "17  workhouse            NaN          NaN            NaN          NaN\n",
                            "18        boy           girl          NaN           girl          NaN\n",
                            "19          .            NaN          NaN            NaN          NaN\n",
                            "20        NaN            NaN          NaN            NaN          NaN\n",
                            "21        NaN            NaN          NaN            NaN          NaN\n",
                            "22        NaN            NaN          NaN            NaN          NaN\n",
                            "23        NaN            NaN          NaN            NaN          NaN\n",
                            "24        NaN            NaN          NaN            NaN          NaN\n",
                            "25        NaN            NaN          NaN            NaN          NaN\n",
                            "26        NaN            NaN          NaN            NaN          NaN\n",
                            "27        NaN            NaN          NaN            NaN          NaN\n",
                            "28        NaN            NaN          NaN            NaN          NaN\n",
                            "29        NaN            NaN          NaN            NaN          NaN\n",
                            "30        NaN            NaN          NaN            NaN          NaN\n",
                            "31        NaN            NaN          NaN            NaN          NaN"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Fix labelling errors\n",
                "\n",
                "new_dfs = {\n",
                "    \"Rick\": \"./data/newly_labelled/intersection_template_rick.xlsx\",\n",
                "    \"Hjalmar\": \"./data/newly_labelled/intersection_template_hjalmar.xlsx\",\n",
                "    \"Artur\": \"./data/newly_labelled/intersection_template_Artur_v2.xlsx\",\n",
                "}\n",
                "\n",
                "for resp in new_dfs.keys():\n",
                "    new_dfs[resp] = load_excel(new_dfs[resp], new_format=True)\n",
                "\n",
                "all_male_sentences = new_dfs[\"Rick\"].original.copy()\n",
                "\n",
                "# Merge the new data\n",
                "base = new_dfs[\"Rick\"]\n",
                "\n",
                "for resp in [\"Hjalmar\", \"Artur\"]:\n",
                "    base.all_female[base.resp == resp] = new_dfs[resp].all_female[\n",
                "        new_dfs[resp].resp == resp\n",
                "    ]\n",
                "    base.all_male[base.resp == resp] = new_dfs[resp].all_male[\n",
                "        new_dfs[resp].resp == resp\n",
                "    ]\n",
                "    base.subj_female[base.resp == resp] = new_dfs[resp].subj_female[\n",
                "        new_dfs[resp].resp == resp\n",
                "    ]\n",
                "    base.subj_male[base.resp == resp] = new_dfs[resp].subj_male[\n",
                "        new_dfs[resp].resp == resp\n",
                "    ]\n",
                "\n",
                "# Replace with the \"real\" original sentences, not the all_male one\n",
                "base.original = phrases.original.iloc[base.idx]\n",
                "\n",
                "def flip_if_needed(\n",
                "    original_phrases: pd.DataFrame,\n",
                "    labelling_female: pd.DataFrame,\n",
                "    labelling_male: pd.DataFrame,\n",
                "):\n",
                "    for i in range(len(original_phrases)):\n",
                "        for j in range(len(original_phrases.columns)):\n",
                "            if (\n",
                "                labelling_female.iloc[i, j] is not None\n",
                "                and original_phrases.iloc[i, j] == labelling_female.iloc[i, j]\n",
                "            ):\n",
                "                labelling_male.iloc[i, j] = all_male_sentences.iloc[i, j]\n",
                "\n",
                "flip_if_needed(\n",
                "    base.original,\n",
                "    base.all_female,\n",
                "    base.all_male\n",
                ")\n",
                "\n",
                "flip_if_needed(\n",
                "    base.original,\n",
                "    base.subj_female,\n",
                "    base.subj_male\n",
                ")\n",
                "\n",
                "# Set the index to the original phrases\n",
                "base.all_female.set_index(base.idx, inplace=True)\n",
                "base.all_male.set_index(base.idx, inplace=True)\n",
                "base.subj_female.set_index(base.idx, inplace=True)\n",
                "base.subj_male.set_index(base.idx, inplace=True)\n",
                "\n",
                "# Replace the original phrases with the new ones\n",
                "phrases.all_female.iloc[base.idx.to_list()] = base.all_female\n",
                "phrases.all_male.iloc[base.idx.to_list()] = base.all_male\n",
                "phrases.subj_female.iloc[base.idx.to_list()] = base.subj_female\n",
                "phrases.subj_male.iloc[base.idx.to_list()] = base.subj_male\n",
                "\n",
                "idx = 1275\n",
                "test_df = pd.DataFrame(\n",
                "    {\n",
                "        \"original\": phrases.original.iloc[idx],\n",
                "        \"all_female\": phrases.all_female.iloc[idx],\n",
                "        \"all_male\": phrases.all_male.iloc[idx],\n",
                "        \"subj_female\": phrases.subj_female.iloc[idx],\n",
                "        \"subj_male\": phrases.subj_male.iloc[idx],\n",
                "    }\n",
                ")\n",
                "test_df"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "r0ZXW2jJwVBp",
            "metadata": {
                "id": "r0ZXW2jJwVBp"
            },
            "source": [
                "# ===================\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "7fa1e870",
            "metadata": {
                "id": "7fa1e870"
            },
            "outputs": [],
            "source": [
                "def change_words(original_phrase, ground_truth):\n",
                "    \"\"\"\n",
                "    Replaces the words in the original phrase with the words in the ground truth\n",
                "    \"\"\"\n",
                "\n",
                "    new_phrase = original_phrase.copy()\n",
                "    for j in list(ground_truth.index):\n",
                "        if not pd.isna(ground_truth.loc[j]):\n",
                "            new_phrase.loc[j] = ground_truth.loc[j]\n",
                "\n",
                "    return list(new_phrase)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "85372cea",
            "metadata": {
                "id": "85372cea"
            },
            "outputs": [],
            "source": [
                "all_fem = []\n",
                "all_male = []\n",
                "subj_fem = []\n",
                "subj_male = []\n",
                "for idx in list(phrases.original.index):\n",
                "    all_fem_phrase = change_words(\n",
                "        phrases.original.loc[idx], phrases.all_female.loc[idx]\n",
                "    )\n",
                "    all_fem.append(all_fem_phrase)\n",
                "\n",
                "    all_male_phrase = change_words(\n",
                "        phrases.original.loc[idx], phrases.all_male.loc[idx]\n",
                "    )\n",
                "    all_male.append(all_male_phrase)\n",
                "\n",
                "    subj_fem_phrase = change_words(\n",
                "        phrases.original.loc[idx], phrases.subj_female.loc[idx]\n",
                "    )\n",
                "    subj_fem.append(subj_fem_phrase)\n",
                "\n",
                "    subj_male_phrase = change_words(\n",
                "        phrases.original.loc[idx], phrases.subj_male.loc[idx]\n",
                "    )\n",
                "    subj_male.append(subj_male_phrase)\n",
                "\n",
                "all_fem = pd.DataFrame(all_fem)\n",
                "all_male = pd.DataFrame(all_male)\n",
                "subj_fem = pd.DataFrame(subj_fem)\n",
                "subj_male = pd.DataFrame(subj_male)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "176d07d5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>0</th>\n",
                            "      <th>1</th>\n",
                            "      <th>2</th>\n",
                            "      <th>3</th>\n",
                            "      <th>4</th>\n",
                            "      <th>5</th>\n",
                            "      <th>6</th>\n",
                            "      <th>7</th>\n",
                            "      <th>8</th>\n",
                            "      <th>9</th>\n",
                            "      <th>...</th>\n",
                            "      <th>19</th>\n",
                            "      <th>20</th>\n",
                            "      <th>21</th>\n",
                            "      <th>22</th>\n",
                            "      <th>23</th>\n",
                            "      <th>24</th>\n",
                            "      <th>25</th>\n",
                            "      <th>26</th>\n",
                            "      <th>27</th>\n",
                            "      <th>28</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>Original Phrase</th>\n",
                            "      <td>Shortly</td>\n",
                            "      <td>afterwards</td>\n",
                            "      <td>,</td>\n",
                            "      <td>he</td>\n",
                            "      <td>visits</td>\n",
                            "      <td>Netherfield</td>\n",
                            "      <td>,</td>\n",
                            "      <td>Mr.</td>\n",
                            "      <td>Bingley</td>\n",
                            "      <td>'s</td>\n",
                            "      <td>...</td>\n",
                            "      <td>.</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>+ Female All Ground Truth</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>she</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Mrs.</td>\n",
                            "      <td>surname_1</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>= Female Phrase</th>\n",
                            "      <td>Shortly</td>\n",
                            "      <td>afterwards</td>\n",
                            "      <td>,</td>\n",
                            "      <td>she</td>\n",
                            "      <td>visits</td>\n",
                            "      <td>Netherfield</td>\n",
                            "      <td>,</td>\n",
                            "      <td>Mrs.</td>\n",
                            "      <td>surname_1</td>\n",
                            "      <td>'s</td>\n",
                            "      <td>...</td>\n",
                            "      <td>.</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>3 rows × 29 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                0           1    2    3       4            5   \\\n",
                            "Original Phrase            Shortly  afterwards    ,   he  visits  Netherfield   \n",
                            "+ Female All Ground Truth      NaN         NaN  NaN  she     NaN          NaN   \n",
                            "= Female Phrase            Shortly  afterwards    ,  she  visits  Netherfield   \n",
                            "\n",
                            "                            6     7          8    9   ...   19  20  21  22  \\\n",
                            "Original Phrase              ,   Mr.    Bingley   's  ...    . NaN NaN NaN   \n",
                            "+ Female All Ground Truth  NaN  Mrs.  surname_1  NaN  ...  NaN NaN NaN NaN   \n",
                            "= Female Phrase              ,  Mrs.  surname_1   's  ...    . NaN NaN NaN   \n",
                            "\n",
                            "                           23  24  25  26  27  28  \n",
                            "Original Phrase           NaN NaN NaN NaN NaN NaN  \n",
                            "+ Female All Ground Truth NaN NaN NaN NaN NaN NaN  \n",
                            "= Female Phrase           NaN NaN NaN NaN NaN NaN  \n",
                            "\n",
                            "[3 rows x 29 columns]"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Example how the phrases look like\n",
                "\n",
                "example_df = pd.DataFrame(\n",
                "    [\n",
                "        list(phrases.original.loc[0]),\n",
                "        list(phrases.all_female.loc[0]),\n",
                "        list(all_fem.loc[0]),\n",
                "    ],\n",
                "    index=[\"Original Phrase\", \"+ Female All Ground Truth\", \"= Female Phrase\"],\n",
                ")\n",
                "\n",
                "example_df"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ac7fbb53",
            "metadata": {
                "id": "ac7fbb53"
            },
            "source": [
                "## Changes to the names and surnames\n",
                "+ for the surnames I deleted the ones that had \"'\" such as O'brain (that's why there are only 248 surnames and not 250)\n",
                "+ for both I deleted the (sur)names that ended in \"s\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "b4b40206",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "b4b40206",
                "outputId": "0dfe9b46-28ef-4475-b252-d75e577682b1"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(250, 1) (250, 1) (248, 1)\n"
                    ]
                }
            ],
            "source": [
                "female_names = pd.read_csv(os.path.join(DATA_PATH, 'Top250Female1996-2019.txt'), lineterminator=\"\\n\", header=None)\n",
                "male_names = pd.read_csv(os.path.join(DATA_PATH, 'Top250Male1996-2019.txt'), lineterminator=\"\\n\", header=None)\n",
                "surnames = pd.read_csv(os.path.join(DATA_PATH, 'Top250Surnames1991-2000.txt'), lineterminator=\"\\n\", header=None) \n",
                "\n",
                "print(female_names.shape,male_names.shape,surnames.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "1bfddab1",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "1bfddab1",
                "outputId": "bdbe1cf4-fb0b-405d-aa04-aeeddef2e33e"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "245 231 193\n"
                    ]
                }
            ],
            "source": [
                "female_names = pd.DataFrame([name for name in list(female_names[0]) if name[-1] != \"s\"])\n",
                "male_names = pd.DataFrame([name for name in list(male_names[0]) if name[-1] != \"s\"])\n",
                "surnames = pd.DataFrame(\n",
                "    [name for name in list(surnames[0]) if (name[-1] != \"s\" or name.find(\"'\") != -1)]\n",
                ")\n",
                "\n",
                "female_names = list(name[0] for name in female_names.values)\n",
                "male_names = list(name[0] for name in male_names.values)\n",
                "surnames = list(name[0] for name in surnames.values)\n",
                "\n",
                "print(len(female_names), len(male_names), len(surnames))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "76960d18",
            "metadata": {
                "id": "76960d18"
            },
            "outputs": [],
            "source": [
                "def change_names(phrase):\n",
                "    \"\"\"\n",
                "    Replace \"name_male_1\", \"name_female_1\" and \"surname_1\" / \"surname_1_pl\" with random names from the lists.\n",
                "\n",
                "    The number determines the index of the name in the list and \"surname_1_pl\" is the plural form of the surname.\n",
                "    \"\"\"\n",
                "    p = phrase.copy()\n",
                "\n",
                "    for word_idx in list(p.index):\n",
                "        if str(p.loc[word_idx]).startswith(\"name_male\"):\n",
                "            # Replace male name\n",
                "            idx = int(p.loc[word_idx][-1]) - 1\n",
                "            p.loc[word_idx] = male_names[idx]\n",
                "        elif str(p.loc[word_idx]).startswith(\"name_female\"):\n",
                "            # Replace female name\n",
                "            idx = int(p.loc[word_idx][-1]) - 1\n",
                "            p.loc[word_idx] = female_names[idx]\n",
                "        elif str(p.loc[word_idx]).startswith(\"surname\"):\n",
                "            if p.loc[word_idx][-2:] == \"pl\":\n",
                "                # Replace plural surname\n",
                "                idx = int(p.loc[word_idx][-4]) - 1\n",
                "                p.loc[word_idx] = surnames[idx] + \"s\"\n",
                "            else:\n",
                "                # Replace singular surname\n",
                "                idx = int(p.loc[word_idx][-1]) - 1\n",
                "                p.loc[word_idx] = surnames[idx]\n",
                "    return p"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "c3f675fa",
            "metadata": {
                "id": "c3f675fa"
            },
            "outputs": [],
            "source": [
                "final_all_fem = []\n",
                "final_all_male = []\n",
                "final_subj_fem = []\n",
                "final_subj_male = []\n",
                "for idx in all_fem.index:\n",
                "    random.shuffle(female_names)\n",
                "    random.shuffle(male_names)\n",
                "    random.shuffle(surnames)\n",
                "\n",
                "    phrase1 = change_names(all_fem.iloc[idx])\n",
                "    final_all_fem.append(phrase1)\n",
                "\n",
                "    phrase2 = change_names(all_male.iloc[idx])\n",
                "    final_all_male.append(phrase2)\n",
                "\n",
                "    phrase3 = change_names(subj_fem.iloc[idx])\n",
                "    final_subj_fem.append(phrase3)\n",
                "\n",
                "    phrase4 = change_names(subj_male.iloc[idx])\n",
                "    final_subj_male.append(phrase4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "3c2d35ca",
            "metadata": {
                "id": "3c2d35ca"
            },
            "outputs": [],
            "source": [
                "final_all_fem = pd.DataFrame(final_all_fem)\n",
                "final_all_male = pd.DataFrame(final_all_male)\n",
                "final_subj_fem = pd.DataFrame(final_subj_fem)\n",
                "final_subj_male = pd.DataFrame(final_subj_male)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "4efa9f5c",
            "metadata": {
                "id": "4efa9f5c"
            },
            "outputs": [],
            "source": [
                "def create_train_val_datasets(final_male, final_female):\n",
                "    SEED = 1234\n",
                "    random.seed(SEED)\n",
                "    frac = 0.8\n",
                "\n",
                "    # creating training and validation indexes\n",
                "    indexes = list(final_male.index)\n",
                "    train_idx = random.sample(indexes, k=int(len(indexes) * frac))\n",
                "    val_idx = [i for i in list(range(len(final_male))) if i not in train_idx]\n",
                "\n",
                "    # trianing dataset\n",
                "    # selects the lines for the training dataset\n",
                "    # these are two datasets that will then be used to choose between female and male after\n",
                "    df_training_male = final_male.iloc[train_idx]\n",
                "    df_training_female = final_female.iloc[train_idx]\n",
                "\n",
                "    df_training_male.insert(0, \"target\", 1)\n",
                "    df_training_female.insert(0, \"target\", 0)\n",
                "\n",
                "    df_training_male.insert(1, \"sentence_idx\", np.arange(len(train_idx)))\n",
                "    df_training_female.insert(1, \"sentence_idx\", np.arange(len(train_idx)))\n",
                "\n",
                "    # concatenate dataframes to create dataset\n",
                "    training_df = pd.concat([df_training_male, df_training_female])\n",
                "\n",
                "    # validation dataset\n",
                "    # selects the lines for the validation dataset\n",
                "    df_validation_male = final_male.iloc[val_idx]\n",
                "    df_validation_female = final_female.iloc[val_idx]\n",
                "\n",
                "    df_validation_male.insert(0, \"target\", np.ones(len(df_validation_male)))\n",
                "    df_validation_female.insert(0, \"target\", np.zeros(len(df_validation_female)))\n",
                "\n",
                "    df_validation_male.insert(1, \"sentence_idx\", np.arange(len(val_idx)))\n",
                "    df_validation_female.insert(1, \"sentence_idx\", np.arange(len(val_idx)))\n",
                "\n",
                "\n",
                "    return training_df, df_validation_male, df_validation_female, val_idx, train_idx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "a4c7d55d",
            "metadata": {
                "id": "a4c7d55d"
            },
            "outputs": [],
            "source": [
                "(\n",
                "    training_df_all,\n",
                "    df_validation_male_all,\n",
                "    df_validation_female_all,\n",
                "    val_idx_all,\n",
                "    train_idx_all,\n",
                ") = create_train_val_datasets(final_all_male, final_all_fem)\n",
                "\n",
                "(\n",
                "    training_df_subj,\n",
                "    df_validation_male_subj,\n",
                "    df_validation_female_subj,\n",
                "    val_idx_subj,\n",
                "    train_idx_subj,\n",
                ") = create_train_val_datasets(final_subj_male, final_subj_fem)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "9e875f38",
            "metadata": {
                "id": "9e875f38"
            },
            "outputs": [],
            "source": [
                "files = {\n",
                "    \"training_df_all.pkl\": training_df_all,\n",
                "    \"df_validation_male_all.pkl\": df_validation_male_all,\n",
                "    \"df_validation_female_all.pkl\": df_validation_female_all,\n",
                "    \"training_df_subj.pkl\": training_df_subj,\n",
                "    \"df_validation_male_subj.pkl\": df_validation_male_subj,\n",
                "    \"df_validation_female_subj.pkl\": df_validation_female_subj\n",
                "}\n",
                "\n",
                "for filename, df in files.items():\n",
                "    with open(os.path.join(OUTPUT_PATH, filename), \"wb\") as f:\n",
                "        pickle.dump(df, f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "503bdf69",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_gt(original_phrases, female_gt, male_gt):\n",
                "    gt_out = pd.DataFrame(np.zeros(phrases.subj_female.shape))\n",
                "    offset = 3\n",
                "\n",
                "    for i in range(len(original_phrases)):\n",
                "        phrase_f = female_gt.iloc[i]\n",
                "        phrase_m = male_gt.iloc[i]\n",
                "\n",
                "        for word_idx in range(len(phrase_f)):\n",
                "            if str(phrase_f[word_idx + offset]) != str(phrase_m[word_idx + offset]):\n",
                "                gt_out.iloc[i][word_idx] = 1\n",
                "    \n",
                "    return gt_out\n",
                "\n",
                "\n",
                "# Ground truth for change type \"all\"\n",
                "gt_all = create_gt(phrases.original, phrases.all_female, phrases.all_male)\n",
                "gt_all_val = gt_all.loc[val_idx_all]\n",
                "gt_all_train = gt_all.loc[train_idx_all]\n",
                "\n",
                "# Concat ground truth to match training set (df_training_male, df_training_female)\n",
                "gt_all_train = pd.concat([gt_all_train, gt_all_train])\n",
                "\n",
                "# Ground truth for change type \"subj\"\n",
                "gt_subj = create_gt(phrases.original, phrases.subj_female, phrases.subj_male)\n",
                "gt_subj_val = gt_subj.loc[val_idx_subj]\n",
                "gt_subj_train = gt_subj.loc[train_idx_subj]\n",
                "\n",
                "# Concat ground truth to match training set (df_training_male, df_training_female)\n",
                "gt_subj_train = pd.concat([gt_subj_train, gt_subj_train])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "afAqTBtDFtKc",
            "metadata": {
                "id": "afAqTBtDFtKc"
            },
            "outputs": [],
            "source": [
                "gt_files = {\n",
                "    \"gt_subj_val.pkl\": gt_subj_val,\n",
                "    \"gt_subj_train.pkl\": gt_subj_train,\n",
                "    \"gt_all_val.pkl\": gt_all_val,\n",
                "    \"gt_all_train.pkl\": gt_all_train\n",
                "}\n",
                "\n",
                "for filename, df in gt_files.items():\n",
                "    with open(os.path.join(OUTPUT_PATH, filename), \"wb\") as f:\n",
                "        pickle.dump(df, f)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "12996198",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Male</th>\n",
                            "      <th>Female</th>\n",
                            "      <th>Ground Truth</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>To</td>\n",
                            "      <td>To</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>highlight</td>\n",
                            "      <td>highlight</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>the</td>\n",
                            "      <td>the</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>hypocrisy</td>\n",
                            "      <td>hypocrisy</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>required</td>\n",
                            "      <td>required</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>to</td>\n",
                            "      <td>to</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>condone</td>\n",
                            "      <td>condone</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>slavery</td>\n",
                            "      <td>slavery</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>within</td>\n",
                            "      <td>within</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>an</td>\n",
                            "      <td>an</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>ostensibly</td>\n",
                            "      <td>ostensibly</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>moral</td>\n",
                            "      <td>moral</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>12</th>\n",
                            "      <td>system</td>\n",
                            "      <td>system</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13</th>\n",
                            "      <td>,</td>\n",
                            "      <td>,</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>Zac</td>\n",
                            "      <td>Lauren</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15</th>\n",
                            "      <td>has</td>\n",
                            "      <td>has</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>16</th>\n",
                            "      <td>Ibrahim</td>\n",
                            "      <td>Nadia</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>17</th>\n",
                            "      <td>'s</td>\n",
                            "      <td>'s</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>18</th>\n",
                            "      <td>father</td>\n",
                            "      <td>mother</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19</th>\n",
                            "      <td>enslave</td>\n",
                            "      <td>enslave</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>20</th>\n",
                            "      <td>his</td>\n",
                            "      <td>her</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21</th>\n",
                            "      <td>son</td>\n",
                            "      <td>daughter</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>22</th>\n",
                            "      <td>,</td>\n",
                            "      <td>,</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>23</th>\n",
                            "      <td>isolate</td>\n",
                            "      <td>isolate</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>24</th>\n",
                            "      <td>him</td>\n",
                            "      <td>her</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25</th>\n",
                            "      <td>and</td>\n",
                            "      <td>and</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>26</th>\n",
                            "      <td>beat</td>\n",
                            "      <td>beat</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>27</th>\n",
                            "      <td>him</td>\n",
                            "      <td>her</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28</th>\n",
                            "      <td>.</td>\n",
                            "      <td>.</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          Male      Female Ground Truth\n",
                            "0           To          To          0.0\n",
                            "1    highlight   highlight          0.0\n",
                            "2          the         the          0.0\n",
                            "3    hypocrisy   hypocrisy          0.0\n",
                            "4     required    required          0.0\n",
                            "5           to          to          0.0\n",
                            "6      condone     condone          0.0\n",
                            "7      slavery     slavery          0.0\n",
                            "8       within      within          0.0\n",
                            "9           an          an          0.0\n",
                            "10  ostensibly  ostensibly          0.0\n",
                            "11       moral       moral          0.0\n",
                            "12      system      system          0.0\n",
                            "13           ,           ,          0.0\n",
                            "14         Zac      Lauren          1.0\n",
                            "15         has         has          0.0\n",
                            "16     Ibrahim       Nadia          1.0\n",
                            "17          's          's          0.0\n",
                            "18      father      mother          1.0\n",
                            "19     enslave     enslave          0.0\n",
                            "20         his         her          1.0\n",
                            "21         son    daughter          1.0\n",
                            "22           ,           ,          0.0\n",
                            "23     isolate     isolate          0.0\n",
                            "24         him         her          1.0\n",
                            "25         and         and          0.0\n",
                            "26        beat        beat          0.0\n",
                            "27         him         her          1.0\n",
                            "28           .           .          0.0"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Sanity check\n",
                "\n",
                "idx = df_validation_male_all[1] == \"highlight\"\n",
                "cur_gt = gt_all_val[idx].iloc[0]\n",
                "cur_sentence_male = df_validation_male_all[idx].iloc[0][2:]\n",
                "cur_sentence_female = df_validation_female_all[idx].iloc[0][2:]\n",
                "\n",
                "pd.DataFrame([\n",
                "    cur_sentence_male,\n",
                "    cur_sentence_female,\n",
                "    cur_gt\n",
                "], index=[\"Male\", \"Female\", \"Ground Truth\"]).T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7c5f548c",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
