{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "b55d4e5f",
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "9f7df40d",
            "metadata": {
                "id": "9f7df40d"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import random\n",
                "import os\n",
                "\n",
                "SEED = 1234\n",
                "random.seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "\n",
                "DATA_PATH = \"./data\"\n",
                "OUTPUT_PATH = \"../dataset\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "1fd4fdc8",
            "metadata": {
                "id": "1fd4fdc8"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
                        "[nltk_data]     /home/hjal/nltk_data...\n",
                        "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
                        "[nltk_data]       date!\n",
                        "[nltk_data] Downloading package punkt to /home/hjal/nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "from labelling import Labelling\n",
                "\n",
                "data_path = os.path.join(\"./labelling.json\")\n",
                "labelling = Labelling(data_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ac7fbb53",
            "metadata": {
                "id": "ac7fbb53"
            },
            "source": [
                "## Changes to the names and surnames\n",
                "+ for the surnames I deleted the ones that had \"'\" such as O'brain (that's why there are only 248 surnames and not 250)\n",
                "+ for both I deleted the (sur)names that ended in \"s\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "b4b40206",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "b4b40206",
                "outputId": "0dfe9b46-28ef-4475-b252-d75e577682b1"
            },
            "outputs": [],
            "source": [
                "surnames = pd.read_csv(os.path.join(DATA_PATH, 'Top250Surnames1991-2000.txt'), lineterminator=\"\\n\", header=None) \n",
                "surnames = [name for name in list(surnames[0]) if (name[-1] != \"s\" or name.find(\"'\") != -1)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "34881373",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_ds, test_ds = labelling.to_dataset(surnames)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "7c5f548c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "def to_jsonl_file(output_file: str, lines: list[dict]):\n",
                "    with open(output_file, 'w') as file:\n",
                "        for line in lines:\n",
                "            file.write(json.dumps(line, ensure_ascii=False) + '\\n')\n",
                "\n",
                "def save_dataset(train_ds, test_ds, version_mapping):\n",
                "    for name, dataset in [(\"train\", train_ds), (\"test\", test_ds)]:\n",
                "        for version_name, version in dataset.items():\n",
                "            version_name = version_mapping[version_name]\n",
                "            output_dir = os.path.join(OUTPUT_PATH, version_name)\n",
                "            os.makedirs(output_dir, exist_ok=True)\n",
                "\n",
                "            output_file = os.path.join(output_dir, f\"{name}.jsonl\")\n",
                "            lines = [entry.model_dump() for entry in version]\n",
                "            to_jsonl_file(output_file, lines)\n",
                "\n",
                "save_dataset(train_ds, test_ds, {\n",
                "    \"all\": \"non_binary_gender_all\",\n",
                "    \"subj\": \"non_binary_gender_subj\"\n",
                "})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "3c92a3d3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create binary version\n",
                "\n",
                "for sentence in labelling:\n",
                "    for version in sentence.versions:\n",
                "        if \"neutral\" in sentence.versions[version].gender:\n",
                "            del sentence.versions[version].gender[\"neutral\"]\n",
                "\n",
                "train_ds_binary, test_ds_binary = labelling.to_dataset(surnames)\n",
                "\n",
                "save_dataset(train_ds_binary, test_ds_binary, {\n",
                "    \"all\": \"binary_gender_all\",\n",
                "    \"subj\": \"binary_gender_subj\"\n",
                "})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b773173",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
